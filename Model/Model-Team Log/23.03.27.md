### KIEMS 방문록

이전에 작성한 거에 branch conflict를 방지하고자 브런치만 업데이트하고 붙여넣기만 하려고 했는데 다른 걸 복사해버려서 날라갔다... 굉장히 허무하다. 이런 걸 또 작성해야 한다니.

다중 분류 모델을 구성하기 전에 KIMES에 방문한 것에 대한 기록을 남기고자 한다.

코엑스의 1층과 3층에서 A~D홀로 이루어진 전시장에서 의료기기를 전시하는 박람회다. 2년 전에 KAIST에서 진단기기를 개발해서는 학술회처럼 발표하고 있는 것을 보고 올해에도 그런 팀이 있지 않을까
하는 기대를 가지고 갔었다.

C, D홀이 영상 진단기기 파트였기에 거기에서 내가 원하는 것을 볼 수 있었다. 한 기기에 대해 자세히 설명해보자면 발바닥을 통해 무게중심을 파악하며 신체도 함께 촬영하며 쏠림의 정도를 측정하는
기기였다. 그와 동시에 7여 가지의 질병을 진단하는 AI도 있었다. 개발자 분께서 직접 설명해주셨기에 이에 대해 자세히 들을 수 있었다.

의료 AI의 현 기술의 상황와 한계점에 대한 것이다. 모델에 관해서도 조금이나마 들을 수 있었다. 그 중에 이상적인 모델에 대한 내용도 여쭤봤는데, 이상적이라는 것에 대한 기준은 다르기에 병원에서
정한 것이나 논문의 내용을 바탕으로 설정한다고 했다.

이것 외에 그렇게 기억에 남는 작품은 없었다. 인공지능 기술이 발달해서 획기적인 무언가가 있을까 싶었지만 기대에 미치지는 못했다. 하지만 확실히 다른 건 이젠 인공지능의 기술이 있다며 앞세우고
있진 않다는 점이었다. 당연히 포함되어 있는 기술로 취급된 것을 알 수 있었다.

---

## 다중 분류 모델

우선 이전의 코드를 모두 실행시켜준다.

![image](https://user-images.githubusercontent.com/84713532/227820518-4adae6bc-b6c1-44ed-a964-280948e6f17e.png)

![image](https://user-images.githubusercontent.com/84713532/227820500-4197552b-6720-4217-8441-50bbe0e870b2.png)

데이터셋 구성부터 시각화까지 문제없이 오케이.. 이제 데이터를 분할시키고 모델을 구성하여 훈련을 실행하는 코드까지 완료해보겠다.


## 데이터 분할

```py
trainset, testset = random_split(trainset, [960, 240])
```

![image](https://user-images.githubusercontent.com/84713532/227823333-939a9f49-86b0-4059-9b77-690f72024994.png)

우선 trainset, testset으로 나눠봤다. 개수까지는 잘 나눠진 것을 확인할 수 있다.

![image](https://user-images.githubusercontent.com/84713532/227823385-02b91975-c4ba-4632-8fe8-026d937a7c54.png)

더 다양하게 시각화를 해봤다. 문제점 하나를 발견했다. 이미지는 분명 adress같아보이는데 라벨은 5(follow)라고 한다. json file부터가 잘못 기입되었고, 이걸 확인하지 않고 분류된대로
폴더에 넣어 정리해서 생긴 문제점이다..

얼마 해보지도 않았는데 이런 라벨링 결과가 보이니 조금 걱정스럽다. 하지만 모델 간의 성능을 비교하는 것이기에 큰 문제는 되지 않을 거라 생각하고 싶다.

이제 testset에서 validationset으로 더 나누어서 8:1:1의 비율로 960:120:120으로 나누겠다.

random_split을 이용하니 잘 섞이는 것은 의심치 않겠다.

```py
testset, valset = random_split(testset, [120, 120])
```

![image](https://user-images.githubusercontent.com/84713532/227824155-c7774f7c-0148-45f6-bfb0-0ca5b62c5a12.png)

잘 나눠졌다. cell을 비효율적으로 사용하고 있는 것 같아서 같은 cell로 옮겨서 다시 해보려고 하니까 오류가 발생했다. 이미 120개로 나눠진 set에서 또 나누려고 해서 그런 것 같다.

코드만 옮겨놓고 정리해서 실행은 시키지 말아야겠다.

![image](https://user-images.githubusercontent.com/84713532/227824469-523d79c7-8094-4d4d-92ea-38880937202b.png)

이것도 시각화 한번 시켜봤는데 이거 이미지 상태가 좀 심각하다. 너무 진해져서 나오는데 지금은 시각화를 위해 permute를 사용했는데, 모델 학습시킬 때에도 이게 필요한 건지 검토해보고 필요하다면 수정해야겠다. 내가 봐서는 무슨 동작인지 모르겠지만 downswing이라고 라벨값이 붙어있긴 하다.

```py
figure, axes = plt.subplots(nrows=1, ncols=8, figsize=(22, 6))
for i in range(8):
  axes[i].imshow(trainset[i][0].permute(1, 2, 0), cmap='gray')
  axes[i].set_title(trainset[i][1])
```

![image](https://user-images.githubusercontent.com/84713532/227824906-3f599a42-2ab2-424a-83c9-9fa23ec62605.png)

어쩌면 json value가 생각보다 더 난장판이 아닌가 싶다.

```py
labels_map = {0 : 'adress', 1 : 'backswing', 2: 'backswingtop', 3: 'downswing', 4: 'finish', 5: 'follow', 6: 'impact', 7: 'takeback'}

figure, axes = plt.subplots(nrows=4, ncols=8, figsize=(16, 8))
axes = axes.flatten()

for i in range(32):
    rand_i = np.random.randint(0, len(trainset))
    image = trainset[rand_i][0].permute(1, 2, 0)
    axes[i].axis('off')
    axes[i].imshow(image)
    axes[i].set_title(labels_map[trainset[rand_i][1]])   
```

label 값을 숫자에서 이름으로 바꿔주는 과정에서 

```
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
```

이미지 한장당 이런 경고가 계속 발생하는 것을 유심히 보게 되었다. 보니까 정규화된 값을 RGB의 0~255값으로 변경하여 출력하는 것 같았다.
이걸 보고 어쩌면 정규화 때문에 이런 문제가 발생한 게 아닌가 싶었다.

그럼 이걸 해결하기 위한 방안은 두 가지가 있다.

- 정규화를 하지 않는 것.
- 정규화한 이미지를 미리 픽셀값 0~255 범위의 RGB 이미지로 바꿔놓는 것이다.

근데 막상 이걸 적고나니까 정규화는 모델 훈련을 위해 해주는 작업이다. 중요한 건 시각화가 아니라 모델 훈련이다.

원래 모델 훈련 직전에 정규화를 시켜주는데, 정규화된 이미지를 출력하다보니 이런 문제가 발생한 것 같다. (AI는 이런 사진들을 보고 뭘 훈련한다는 걸까)
어쨌든 시각화는 마무리 하겠다.

---

## 모델 구성

모델 부분은 구성 방법과 종류가 매우 다양하기 때문에 많은 실험을 할 수 있다. 그렇기에 기록은 필수적인 요소이다.

#### 우선 구성 방법

- 전이학습
- 범용적인 CNN 모델 뼈대 직접 구성
- 개인적인 모델 구성하기

#### 모델 종류

- ResNet
- GoogleNet
- VGGNet
- EfficientNet
- and so on

위의 여러가지 방법들이 있는데 먼저 준비해두었던 Roboflow에서 제공하는 fast.ai의 모델을 활용해보겠다. Resnet과 EfficientNet이 있던 것 같은데, 비교해보겠다.

```py
!pip install fastai
```

![image](https://user-images.githubusercontent.com/84713532/227827861-73d029f1-bda7-465e-b7c1-d2e1f3b1a6b9.png)

뭐가 이렇게 많아.. 일단 오케이

```py
from fastai.vision import *
```

```py
#follow the link below to get your download code from from Roboflow
!pip install -q roboflow
from roboflow import Roboflow
rf = Roboflow(model_format="folder", notebook="roboflow-resnet")
```

![image](https://user-images.githubusercontent.com/84713532/227827934-388b8075-6482-401a-8637-d13178b83cf9.png)

문제 발생 - API 키가 옳지 않은 형태라고 한다.

![image](https://user-images.githubusercontent.com/84713532/227828148-d8faf789-52fa-4fa7-b966-fa08aa45c7b3.png)

str type이여야 하는데 Nonetype이라고 한다. 이걸 내가 해결할 수 있는 문제인가..?
구글링을 해봐야겠다.

[참고 링크](https://github.com/facebookresearch/detectron2/issues/3649)

문제점을 살펴보니 Environment, 즉, 버전 문제다. 왜 항상 뭐 좀 써보려고 하면 버전이 문제일까.. 다른 선택지가 많은 상황에서 이렇게 버전을 굳이 바꿔가면서 하고 싶진 않은데..
Roboflow 사이트 들어가서 더 찾아봐야겠다.

![image](https://user-images.githubusercontent.com/84713532/227828935-66baed88-b60d-4316-accf-1e505a0f0aef.png)

찾아보니 비록 Yolo5에 관한 내용이지만 Roboflow의 버전을 바꾸는 방법이 있다는 걸 알아냈다.

나도 ResNet을 사용하기 위한 버전을 찾아보거나 모든 버전을 한번씩 모두 실행해보는 방법을 취해야겠다.

하지만 아래로 좀 더 내려보니 버전을 바꿔도 문제는 여전하다고 했고, 이 문제를 해결하기 위해선 jupyter notebook에서 데이터를 처리하고 zip file type으로 바꾼 다음 구글 colab에 올려주면 된다는 내용이었다. 복잡하다.. 그냥 데이터 받아서 쓰도록 만들었어야 되는 거 아닌가. 좋지 않다.





















