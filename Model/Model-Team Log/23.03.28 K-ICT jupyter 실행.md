#### 코랩에서는 outofmemory error가 나고 K-ICT의 가상환경 내의 jupyter notebook에서는 모듈 import error가 발생한다.

동엽님도 이 똑같은 문제에 맞닥드려서 강사님께 여쭤봐서 해결해주셨다고 했다. 그래서 사용해보려고 한다.

![image](https://user-images.githubusercontent.com/84713532/228143034-b442de89-aaac-4284-bb17-4f31a4ebacb3.png)

정말 된다! 그리고 빠르다. 하지만...

```py
model = ResNet101()
from torchsummary import summary
summary(model.cuda(), (3,32,32))
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
```

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
/tmp/ipykernel_89486/1886119461.py in <module>
      1 model = ResNet101()
      2 from torchsummary import summary
----> 3 summary(model.cuda(), (3,32,32))
      4 criterion = nn.CrossEntropyLoss()
      5 optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)

/opt/conda/lib/python3.8/site-packages/torchsummary/torchsummary.py in summary(model, input_size, batch_size, device)
     70     # make a forward pass
     71     # print(x.shape)
---> 72     model(*x)
     73 
     74     # remove these hooks

/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1100         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1101                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1102             return forward_call(*input, **kwargs)
   1103         # Do not call functions when jit is used
   1104         full_backward_hooks, non_full_backward_hooks = [], []

/tmp/ipykernel_89486/3621049645.py in forward(self, x)
     74 
     75     def forward(self, x):
---> 76         out = F.relu(self.bn1(self.conv1(x)))
     77         out = self.layer1(out)
     78         out = self.layer2(out)

/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1118             input = bw_hook.setup_input_hook(input)
   1119 
-> 1120         result = forward_call(*input, **kwargs)
   1121         if _global_forward_hooks or self._forward_hooks:
   1122             for hook in (*_global_forward_hooks.values(), *self._forward_hooks.values()):

/opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py in forward(self, input)
    146             # TODO: if statement only here to tell the jit to skip emitting this when it is None
    147             if self.num_batches_tracked is not None:  # type: ignore[has-type]
--> 148                 self.num_batches_tracked = self.num_batches_tracked + 1  # type: ignore[has-type]
    149                 if self.momentum is None:  # use cumulative moving average
    150                     exponential_average_factor = 1.0 / float(self.num_batches_tracked)

RuntimeError: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
```

cuda와 관련한 문제가 발생했다. 저번에도 이런 비슷한 오류를 만난적 있는데 해결하지 못했던 오류다. GPU 관련해서 코딩한게 이렇게 오류가 나는 거 같은데 어떻게 해결해야 될지 모르겠다.

우선 강사님께서 이전에 터미널에 실행하라고 주신 코드가 있다.

```
$ pip install --upgrade pip
$ conda update -n base conda
$ conda update --all
$ pip install opencv-contrib-python==4.5.5.62
$ pip install opencv-contrib-python-headless==4.5.5.62
$ pip install opencv-python==4.5.5.62
$ pip install opencv-python-headless==4.5.5.62
$  conda install pytorch torchvision cudatoolkit=11.4 -c pytorch -c nvidia
!pip install torchvision==0.14.0
```

이걸 먼저 터미널에서 실행시켜보고 cuda 문제를 해결해보자. 안되면 강사님께 찾아봬서 여쭤봐야겠다.

![image](https://user-images.githubusercontent.com/84713532/228143539-dec3cedd-674d-4265-b06b-f3218852abc4.png)

마지막 코드 실행 중인데 자꾸 뭘 실패했다고 뜨는 거야... 불길하다. 제대로 실행이 안되니까 알아서 이런저런 해결방안대로 하는 것 같은데 시간이 오래 걸린다. 이것 또한 불길하다.

```
Solving environment: \
The environment is inconsistent, please check the package plan carefully
The following packages are causing the inconsistency:

  - conda-forge/linux-64::conda-build==3.21.4=py38h578d9bd_0
\ failed with initial frozen solve. Retrying with flexible solve.

CondaError: KeyboardInterrupt
```

결국 이렇게 떴다... 그래서 우선 cuda 코드를 실행시켜보자.

=> 역시 안된다! 구글링 한번 해보고 강사님께 가보겠다.

### [구글링 후 참고 사이트](https://yjs-program.tistory.com/206)

- 사용 가능 여부를 위해 pytorch 버전 확인

```py
import torch

torch.cuda.is_available()
```

```
Ture
```

- 무슨 차이??

```
import torch

torch.rand(10).cuda()
```

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
/opt/conda/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj)
    700                 type_pprinters=self.type_printers,
    701                 deferred_pprinters=self.deferred_printers)
--> 702             printer.pretty(obj)
    703             printer.flush()
    704             return stream.getvalue()

/opt/conda/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj)
    392                         if cls is not object \
    393                                 and callable(cls.__dict__.get('__repr__')):
--> 394                             return _repr_pprint(obj, self, cycle)
    395 
    396             return _default_pprint(obj, self, cycle)

/opt/conda/lib/python3.8/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle)
    698     """A pprint that just redirects to the normal repr function."""
    699     # Find newlines and replace them with p.break_()
--> 700     output = repr(obj)
    701     lines = output.splitlines()
    702     with p.group():

/opt/conda/lib/python3.8/site-packages/torch/_tensor.py in __repr__(self)
    247             return handle_torch_function(Tensor.__repr__, (self,), self)
    248         # All strings are unicode in Python 3.
--> 249         return torch._tensor_str._str(self)
    250 
    251     def backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None):

/opt/conda/lib/python3.8/site-packages/torch/_tensor_str.py in _str(self)
    413 def _str(self):
    414     with torch.no_grad():
--> 415         return _str_intern(self)

/opt/conda/lib/python3.8/site-packages/torch/_tensor_str.py in _str_intern(inp)
    388                     tensor_str = _tensor_str(self.to_dense(), indent)
    389                 else:
--> 390                     tensor_str = _tensor_str(self, indent)
    391 
    392     if self.layout != torch.strided:

/opt/conda/lib/python3.8/site-packages/torch/_tensor_str.py in _tensor_str(self, indent)
    249         return _tensor_str_with_formatter(self, indent, summarize, real_formatter, imag_formatter)
    250     else:
--> 251         formatter = _Formatter(get_summarized_data(self) if summarize else self)
    252         return _tensor_str_with_formatter(self, indent, summarize, formatter)
    253 

/opt/conda/lib/python3.8/site-packages/torch/_tensor_str.py in __init__(self, tensor)
     88 
     89         else:
---> 90             nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0))
     91 
     92             if nonzero_finite_vals.numel() == 0:

RuntimeError: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
```

어쨌든 이런 오류가 난다.

이 링크에서는 cuda 버전과 pytorch 버전이 호환되지 않아서 생기는 문제라고 한다. 그래서 삭제하고 GPU에 맞는 버전으로 다시 다운받던데..
나는 애초에 GPU가 없다!

그러던 중 강사님의 코드 마지막 줄을 jupyter 내부에서 실행시켜봤다. 그랬더니 뭔가를 열심히 다운받는다. 다 다운받으면 다시 실행시켜봐야겠다.

```py
!pip install torchvision==0.14.0
```

뭔가 되다가 또 안된다. 호환이 안된다고 한다. 계속.. 강사님께 가봐야겠다.

강사님이 해결해주셨다! (base)에서 다운받으면 다른 사람들의 가상환경에도 영향을 끼칠 수 있어서 다운로드가 되지 않도록 해놨다고 하셨다. 그래서 강사님이 dl이라는 가상환경을 만드셔서
따로 다운로드를 받아주셨다. 그랬더니 해결됐다.

![image](https://user-images.githubusercontent.com/84713532/228159693-ea638c50-4bf5-4d11-90d9-8ac0c9e089c2.png)

깔끔하다. 이제 여기서 outofmemory가 발생하는지를 알아봐야겠다.

---

## outofmemory 문제 실험

Colab과 같은 조건에서 ResNet101을 실행해봤다. 결과는 비슷했다. 속도도 비슷하고.

이제 32X32로 줄였던 사이즈를 늘려보겠다. 32X32 => 64X64

강사님께서 최소 64X64는 되어야 한다고 하셨다.

![image](https://user-images.githubusercontent.com/84713532/228161042-1a1cbb3b-7010-4570-abd4-3e61f6af52eb.png)

확실히 깔끔해졌다. 모델 훈련까지 되는지 확인해보겠다.

![image](https://user-images.githubusercontent.com/84713532/228161235-7647baf2-3854-4b7a-a3f4-183c09800614.png)

이제 좀 클럽이 보이는 것 같다.

```
RuntimeError: mat1 and mat2 shapes cannot be multiplied (8x8192 and 2048x8)
```

또 이 에러가 뜬다. 이미지 크기를 이 이상 내릴 순 없다. 그럼 모델의 구조를 한번 키워보자.

모델 구조를 키운다니... 뭔가 확실히 이미지 쪽에서의 문제인데 이 숫자를 바꾸는 방법은 현재 batch_size의 크기 조절과 이미지 크기 조절 뿐이다. 

batch_size는 1까지 줄여봤지만 실행되지 않았다.

---

그냥...전이학습하자

pytorch에서 가져오자 [링크](https://pytorch.org/hub/pytorch_vision_resnet/)

실행 잘된다. 이제 데이터 다시 꾸려서 ResNet뿐만 아니라 여러 모델들을 실행해보며 실험해보도록 하겠다.

그리곤 동엽님의 프레임 자르는 코드를 보고 실행해본 다음, AI가 제대로 동작별로 분류해내는지 확인해봐야겠다. 이 다음엔 비교하는 코드를 완성해야 한다.

# 오 생각보다 할 거 많은데??
