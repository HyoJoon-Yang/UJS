#### 강사님이 제시해주신 방법으로 해보려고 한다...

## 고찰

주어진 시간은 적기에 과정보단 결과에 집중해야 한다. 가장 적절한 방법은 효준님께서 제시해주셨는데, 모범 스윙을 기준으로 플러스마이너스 n을 기준으로 프레임을 가져오도록 하자는 것이었다.

현재까지 mediapipe 영상에 입혀서 PoseDetection까지 완성한 코드가 있으니 남은 과정을 위한 방법은 아래와 같다.

1. 프레임 별로 자르고 캡쳐하는 코드 준비 - 캡쳐하는 코드에 if문으로 조절 가능
2. 동작별로 if문에 들어갈 landmark의 좌표값을 알아낸다.
3. 좌표값을 알기 위해 표준 스윙 영상에서 동작별로 직접 캡쳐해서 필요한 좌표값을 알아낸다.
4. 알아낸 좌표값을 기준으로 플러스마이너스 기준값을 매겨서 라벨값을 만들어준다.
5. 라벨값의 범위에 들어오면 그 부분을 동작별로 인지하게 하고 그 장면을 한장씩 캡쳐하도록 한다.
6. 캡쳐한 이미지를 처음 좌표값을 구하기 위해 캡쳐한 이미지를 기준으로 크고 작음을 비교한다.

---

### 1번

[1번 링크](https://thinking-developer.tistory.com/61)

---

### 2번

좌표값을 알기 위한 코드 (코랩 기준)

- 이미지 업로드

```py
from google.colab import files  
uploaded = files.upload()  
```

- 이미지 확인

```py
import cv2
from google.colab.patches import cv2_imshow
import math
import numpy as np

DESIRED_HEIGHT = 480
DESIRED_WIDTH = 480
def resize_and_show(image):
  h, w = image.shape[:2]
  if h < w:
    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))
  else:
    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))
  cv2_imshow(img)

# Read images with OpenCV.
images = {name: cv2.imread(name) for name in uploaded.keys()}
# Preview the images.
for name, image in images.items():
  print(name)   
  resize_and_show(image)
```

- PoseDetection

```py
import mediapipe as mp
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils 
mp_drawing_styles = mp.solutions.drawing_styles

help(mp_pose.Pose)
```

- mediapipe landmark 입히기

```py
# Run MediaPipe Pose and draw pose landmarks.
with mp_pose.Pose(
    static_image_mode=True, min_detection_confidence=0.5, model_complexity=2) as pose:
  for name, image in images.items():
    # Convert the BGR image to RGB and process it with MediaPipe Pose.
    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    # Print nose landmark.
    image_hight, image_width, _ = image.shape
    if not results.pose_landmarks:
      continue
    print(
      f'Nose coordinates: ('
      f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * image_width}, '
      f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image_hight})'
    )

    # Draw pose landmarks.
    print(f'Pose landmarks of {name}:')
    annotated_image = image.copy()
    mp_drawing.draw_landmarks(
        annotated_image,
        results.pose_landmarks,
        mp_pose.POSE_CONNECTIONS,
        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())
    resize_and_show(annotated_image)
```

- 모든 landmark and 특정 landmark 출력

```py
# Run MediaPipe Pose and plot 3d pose world landmarks.
with mp_pose.Pose(
    static_image_mode=True, min_detection_confidence=0.5, model_complexity=2) as pose:
  for name, image in images.items():
    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    # Print the real-world 3D coordinates of nose in meters with the origin at
    # the center between hips.
    print('Nose world landmark:'),
    print(results.pose_world_landmarks.landmark[mp_pose.PoseLandmark.NOSE])
    
    # Plot pose world landmarks.
    mp_drawing.plot_landmarks(
        results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)
```


순간 굉장히 무서운 생각이 들었다... 아마 이 생각은 적중일 것이다. 이미지 resize를 해주지 않으면 landmark의 값은 중구난방일 것이다.

그럼 우선 box detection 후에 이미지를 resize 해줘야 한다....

혹시 모르니 resize 과정은 맨 뒤로 미루고 하던 걸 하겠다...

---

### 3번

모범 영상

![silversurfer](https://user-images.githubusercontent.com/84713532/229834718-51ff0c2f-4fb9-4f30-b96d-a5d827b2e35f.gif)

adress, backswing, backswingtop, impact, follow, finish 순으로 캡쳐해보겠다.

![image](https://user-images.githubusercontent.com/84713532/229866262-a794060b-fec1-44b0-97dc-bbad78be235d.png)

![image](https://user-images.githubusercontent.com/84713532/229866299-ccaba7d3-2d48-404f-9857-922aff5bcc26.png)

#### mediapipe landmark는 자동으로 resize 되는 것을 확인할 수 있었다. 이제 해당 값을 찾아서 라벨링해주면 된다.

---

### 4번

[빵형 가위바위보 링크](https://www.youtube.com/watch?v=udeQhZHx-00)

여기서 손바닥 landmark 라벨링을 해준 것을 봤다.

![image](https://user-images.githubusercontent.com/84713532/229866573-07bc3359-4090-4faf-a01f-844e8675175f.png)

근데 이상한 점이 있다. 손바닥엔 21개의 landmark가 있는데, 라벨링은 16개만 해줬다는 것이다. 라벨링 방법을 찾아볼 필요가 있다.

![image](https://user-images.githubusercontent.com/84713532/229867464-536c6a05-a60b-4cfc-8f27-aefabb739e30.png)

라벨값은 왼팔이나 오른팔 하나를 기준으로 3개의 landmark를 가지고 할 예정이다.
